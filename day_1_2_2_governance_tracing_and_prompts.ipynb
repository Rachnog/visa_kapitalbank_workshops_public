{"cells":[{"cell_type":"markdown","id":"865498b5","metadata":{"id":"865498b5"},"source":["# Revisiting tracing with Langfuse"]},{"cell_type":"code","execution_count":null,"id":"c146eda7","metadata":{"id":"c146eda7"},"outputs":[],"source":["! pip install langsmith openai langfuse\n","! pip install -qU requests bs4 lxml chromadb langchain langchain-text-splitters langchain-openai\n","! pip install -qU duckduckgo-search langchain-community ddgs"]},{"cell_type":"code","execution_count":null,"id":"4a89a6e8","metadata":{"id":"4a89a6e8"},"outputs":[],"source":["import os\n","\n","os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n","os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_PROJECT\"] = \"\"\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"code","execution_count":null,"id":"7a33926f","metadata":{"id":"7a33926f"},"outputs":[],"source":["# kb_en_to_chroma.py  — minimal & direct\n","import os, re, time, requests\n","from urllib.parse import urljoin, urldefrag\n","from bs4 import BeautifulSoup\n","\n","BASE = \"https://www.kapitalbank.az\"\n","START = f\"{BASE}/en\"\n","UA = {\"User-Agent\": \"kb-minicrawl/0.2\"}\n","TIMEOUT = 15\n","MAX_PAGES = 50\n","\n","def clean_url(u):\n","    u = urldefrag(u)[0]\n","    if not u: return None\n","    if not u.startswith(\"http\"): u = urljoin(BASE, u)\n","    if not u.startswith(START): return None\n","    if re.search(r\"\\.(pdf|jpe?g|png|gif|svg|mp4|zip|docx?|xlsx?)$\", u, re.I): return None\n","    return u\n","\n","def extract_text(html):\n","    s = BeautifulSoup(html, \"lxml\")\n","    for t in s([\"script\",\"style\",\"noscript\",\"svg\",\"footer\",\"nav\",\"header\"]): t.decompose()\n","    n = s.select_one(\"main\") or s.select_one(\"article\") or s.body or s\n","    return \" \".join((n.get_text(\" \", strip=True) if n else s.get_text(\" \", strip=True)).split())\n","\n","visited, queue, pages = set(), [START], []\n","while queue and len(visited) < MAX_PAGES:\n","    url = queue.pop(0)\n","    if url in visited: continue\n","    try:\n","        r = requests.get(url, headers=UA, timeout=TIMEOUT)\n","        if r.ok and \"text/html\" in r.headers.get(\"Content-Type\",\"\"):\n","            txt = extract_text(r.text)\n","            if len(txt) > 200:\n","                pages.append({\"url\": url, \"text\": txt})\n","            s = BeautifulSoup(r.text, \"lxml\")\n","            for a in s.find_all(\"a\", href=True):\n","                u = clean_url(a[\"href\"])\n","                if u and u not in visited:\n","                    queue.append(u)\n","        visited.add(url); time.sleep(0.15)\n","    except requests.RequestException:\n","        visited.add(url)\n","\n","import json\n","\n","# Save the crawled pages data to a file for later use\n","pages_outfile = \"kapitalbank_pages.json\"\n","with open(pages_outfile, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(pages, f, indent=2, ensure_ascii=False)\n","print(f\"Saved {len(pages)} pages to {pages_outfile}\")\n","\n","# Load crawled pages from JSON file to make them available for Chroma processing\n","with open(pages_outfile, \"r\", encoding=\"utf-8\") as f:\n","    pages = json.load(f)\n","print(f\"Loaded {len(pages)} pages from {pages_outfile}\")\n","\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","\n","# ---- LangChain chunking ----\n","splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n","docs, metas = [], []\n","for p in pages:\n","    for chunk in splitter.split_text(p[\"text\"]):\n","        docs.append(chunk)\n","        metas.append({\"url\": p[\"url\"]})\n","\n","# ---- OpenAI embeddings -> Chroma ----\n","persist_dir = \"chroma_kapitalbank\"\n","emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # cheap & solid\n","vs = Chroma.from_texts(\n","    texts=docs,\n","    embedding=emb,\n","    persist_directory=persist_dir,\n","    collection_name=\"kapitalbank_en\",\n","    metadatas=metas,\n",")\n","vs.persist()\n","print(f\"Indexed pages={len(pages)} chunks={len(docs)} into {persist_dir}/ (collection 'kapitalbank_en')\")\n","\n","from langchain_community.vectorstores import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","\n","persist_dir = \"chroma_kapitalbank\"\n","collection_name = \"kapitalbank_en\"\n","emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n","\n","# Load the existing/persisted Chroma vector store\n","vs = Chroma(\n","    persist_directory=persist_dir,\n","    embedding_function=emb,\n","    collection_name=collection_name\n",")"]},{"cell_type":"code","execution_count":null,"id":"923a9cbe","metadata":{"id":"923a9cbe"},"outputs":[],"source":["from langfuse import get_client\n","from langfuse.langchain import CallbackHandler\n","\n","# Initialize Langfuse client (prompt management)\n","langfuse = get_client()\n","# Initialize Langfuse CallbackHandler for Langchain (tracing)\n","langfuse_callback_handler = CallbackHandler()\n","\n","# Create a text prompt\n","langfuse.create_prompt(\n","    name=\"general-agent-prompt\",\n","    type=\"text\",\n","    prompt=\"Answer the user's question using the tools you have. Always check internal knowledge first, then use the web.\",\n","    labels=[\"production\"],  # directly promote to production\n","    # config={\n","    #     \"model\": \"gpt-4o\",\n","    #     \"temperature\": 0.7,\n","    #     \"supported_languages\": [\"en\", \"fr\"],\n","    # },  # optionally, add configs (e.g. model parameters or model tools) or tags\n",")"]},{"cell_type":"markdown","id":"020c38be","metadata":{"id":"020c38be"},"source":["## Tracing in Langfuse"]},{"cell_type":"code","execution_count":null,"id":"1c188308","metadata":{"id":"1c188308"},"outputs":[],"source":["# pip install -U \"langchain>=0.3\" \"langgraph>=0.2\" \"langchain-openai>=1.0.0\" \"langfuse>=2.0.0\"\n","\n","from typing import Any, Dict\n","from langchain.chat_models import init_chat_model\n","from langchain_core.tools import create_retriever_tool, tool, render_text_description\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import create_agent\n","\n","from langfuse import get_client\n","from langfuse.langchain import CallbackHandler\n","from langfuse import observe\n","\n","# --- Langfuse: prompt mgmt + tracing ---\n","langfuse = get_client()\n","lf_cb = CallbackHandler()\n","\n","# Get current production version (with a safe fallback for HA)\n","lf_prompt = langfuse.get_prompt(\n","    \"general-agent-prompt\",\n","    label=\"production\",\n","    type=\"text\",\n","    fallback=\"Answer the user's question. Prefer internal knowledge before the web.\\n\\nTools:\\n{{tools}}\"\n",")\n","\n","# --- Tools (assume your vector store exists as `vs`) ---\n","retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n","retrieve_tool = create_retriever_tool(\n","    retriever=retriever,\n","    name=\"retrieve\",\n","    description=\"Search the internal vector store for passages relevant to the user's question.\"\n",")\n","\n","_ddg = DuckDuckGoSearchRun()\n","@tool(\"duckduckgo_search\")\n","def duckduckgo_search(query: str) -> str:\n","    \"\"\"Search the web with DuckDuckGo and return a brief summary of top results.\"\"\"\n","    return _ddg.run(query)\n","\n","TOOLS = [retrieve_tool, duckduckgo_search]\n","\n","# --- Model: respect prompt.config if set; otherwise default ---\n","cfg = lf_prompt.config or {}\n","model_id = cfg.get(\"model\", \"openai:gpt-4o-mini\")\n","temperature = float(cfg.get(\"temperature\", 0))\n","model = init_chat_model(model_id, temperature=temperature)\n","\n","# --- Build system prompt from Langfuse prompt ---\n","tools_desc = render_text_description(TOOLS)\n","if \"{{tools}}\" in (lf_prompt.prompt or \"\"):\n","    system_prompt = lf_prompt.compile(tools=tools_desc)  # render {{tools}}\n","else:\n","    # If your prompt has no placeholder, just append a tool section.\n","    system_prompt = (lf_prompt.prompt or \"\") + f\"\\n\\n# Tools\\n{tools_desc}\"\n","\n","# --- Agent ---\n","@observe()  # traces the function; pair with the callback on invoke\n","def agentic_solution(inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:\n","    q: str = inputs[\"question\"]\n","\n","    agent = create_agent(\n","        model=model,\n","        tools=TOOLS,\n","        system_prompt=system_prompt,  # accepts a plain string\n","    )\n","\n","    res = agent.invoke(\n","        {\"messages\": [{\"role\": \"user\", \"content\": q}]},\n","        config={\"callbacks\": [lf_cb]},  # Langfuse tracing\n","    )\n","\n","    # Robustly extract final text (dict w/ \"messages\" or AIMessage)\n","    msg = res[\"messages\"][-1].content if isinstance(res, dict) and \"messages\" in res else getattr(res, \"content\", str(res))\n","    return {\"answer\": msg.strip()}\n"]},{"cell_type":"code","execution_count":null,"id":"d4a3c113","metadata":{"id":"d4a3c113"},"outputs":[],"source":["out = agentic_solution({\"question\": 'Where Kapitalbank is located?'})\n","print(out)"]},{"cell_type":"markdown","id":"b919cbf9","metadata":{"id":"b919cbf9"},"source":["## Managing sessions of multiple step conversations"]},{"cell_type":"code","execution_count":null,"id":"7f573224","metadata":{"id":"7f573224"},"outputs":[],"source":["# --- Notebook chatbot: simple ask() API with Langfuse Session + tracing ---\n","# Paste this cell AFTER your base setup (where you already defined: langfuse, lf_cb, lf_prompt, model, TOOLS, system_prompt)\n","\n","from uuid import uuid4\n","from typing import Dict, List, Optional\n","from langfuse import observe\n","\n","# Optional: link generations to this exact Langfuse prompt version\n","try:\n","    LF_PROMPT_META = {\n","        \"name\": getattr(lf_prompt, \"name\", \"general-agent-prompt\"),\n","        \"version\": getattr(lf_prompt, \"version\", None),\n","        \"label\": \"production\",\n","        \"id\": getattr(lf_prompt, \"id\", None),\n","    }\n","except NameError:\n","    LF_PROMPT_META = None\n","\n","# Session + cached agent\n","SESSION: Dict[str, Optional[str] | List[Dict[str, str]]] = {\"id\": None, \"history\": []}\n","_AGENT = None\n","\n","def start_session(session_id: Optional[str] = None):\n","    \"\"\"Start or reset a session (also clears chat history).\"\"\"\n","    SESSION[\"id\"] = session_id or f\"session-{uuid4()}\"\n","    SESSION[\"history\"] = []\n","    print(f\"Session: {SESSION['id']}\")\n","\n","def _get_agent():\n","    \"\"\"Build the agent once, bind Langfuse callback + (optional) prompt metadata.\"\"\"\n","    global _AGENT\n","    if _AGENT is None:\n","        # ensure LLM/tool generations are traced\n","        m = model.with_config(callbacks=[lf_cb])\n","        a = create_agent(model=m, tools=TOOLS, system_prompt=system_prompt).with_config(callbacks=[lf_cb])\n","        # attach prompt metadata to MODEL path so Linked Generations show under the prompt\n","        if LF_PROMPT_META:\n","            # bind to both model and agent to be safe\n","            m = m.with_config(metadata={\"langfuse_prompt\": LF_PROMPT_META})\n","            a = a.with_config(metadata={\"langfuse_prompt\": LF_PROMPT_META})\n","        _AGENT = a\n","    return _AGENT\n","\n","@observe(name=\"nb_turn\", as_type=\"chain\")   # was: as_type=\"trace\"\n","def _turn(messages: List[Dict[str, str]], session_id: Optional[str]):\n","    \"\"\"One traced turn; attaches to Langfuse Session while an active span exists.\"\"\"\n","    if session_id:\n","        # attach all spans in this trace to the same Session\n","        try:\n","            langfuse.update_current_trace(session_id=session_id)\n","        except Exception:\n","            pass\n","    agent = _get_agent()\n","    return agent.invoke({\"messages\": messages}, config={\"callbacks\": [lf_cb]})\n","\n","def ask(q: str) -> str:\n","    \"\"\"Send a user message; returns assistant reply and updates history.\"\"\"\n","    if not SESSION[\"id\"]:\n","        start_session()\n","\n","    msgs = SESSION[\"history\"] + [{\"role\": \"user\", \"content\": q}]\n","    res = _turn(msgs, SESSION[\"id\"])\n","\n","    reply = (\n","        res[\"messages\"][-1].content\n","        if isinstance(res, dict) and \"messages\" in res\n","        else getattr(res, \"content\", str(res))\n","    ).strip()\n","\n","    SESSION[\"history\"].extend(\n","        [{\"role\": \"user\", \"content\": q}, {\"role\": \"assistant\", \"content\": reply}]\n","    )\n","    return reply\n","\n","def chat_history() -> List[Dict[str, str]]:\n","    \"\"\"Return the current conversation history.\"\"\"\n","    return SESSION[\"history\"]"]},{"cell_type":"code","execution_count":null,"id":"af0cb790","metadata":{"id":"af0cb790"},"outputs":[],"source":["start_session()\n","ask(\"Where Kapitalbank is located?\")\n","ask(\"What products does it offer?\")\n","chat_history()\n","start_session()  # reset with a new session id"]},{"cell_type":"markdown","id":"6c7ea4b1","metadata":{"id":"6c7ea4b1"},"source":["## Multiple users conversations"]},{"cell_type":"code","execution_count":null,"id":"0eed45fd","metadata":{"id":"0eed45fd"},"outputs":[],"source":["# --- Multi-user / multi-session chat runner for notebooks (no widgets) ---\n","\n","from uuid import uuid4\n","from typing import List, Dict, Optional\n","from langfuse import observe\n","\n","# (Optional) link generations to the exact managed prompt version\n","try:\n","    LF_PROMPT_META = {\n","        \"name\": getattr(lf_prompt, \"name\", \"general-agent-prompt\"),\n","        \"version\": getattr(lf_prompt, \"version\", None),\n","        \"label\": \"production\",\n","        \"id\": getattr(lf_prompt, \"id\", None),\n","    }\n","except NameError:\n","    LF_PROMPT_META = None\n","\n","# Build once; bind Langfuse callback (so all LLM/tool calls are traced)\n","_model = model.with_config(callbacks=[lf_cb])\n","_agent = create_agent(model=_model, tools=TOOLS, system_prompt=system_prompt).with_config(callbacks=[lf_cb])\n","if LF_PROMPT_META:\n","    # help the Prompt → Linked Generations tab\n","    _agent = _agent.with_config(metadata={\"langfuse_prompt\": LF_PROMPT_META})\n","\n","@observe(name=\"nb_turn\", as_type=\"chain\")\n","def _turn(messages: List[Dict[str, str]], session_id: str, user_id: str):\n","    # Attach this active span to Langfuse User + Session\n","    try:\n","        langfuse.update_current_trace(session_id=session_id, user_id=user_id, name=\"notebook-chat\")\n","    except Exception:\n","        pass\n","    return _agent.invoke({\"messages\": messages}, config={\"callbacks\": [lf_cb]})\n","\n","class ChatSession:\n","    \"\"\"One user's conversation session (keeps its own id + history).\"\"\"\n","    def __init__(self, user_id: str, session_id: Optional[str] = None):\n","        self.user_id = user_id\n","        self.session_id = session_id or f\"session-{uuid4()}\"\n","        self.history: List[Dict[str, str]] = []\n","\n","    def ask(self, q: str) -> str:\n","        msgs = self.history + [{\"role\": \"user\", \"content\": q}]\n","        res = _turn(msgs, session_id=self.session_id, user_id=self.user_id)\n","        reply = (\n","            res[\"messages\"][-1].content\n","            if isinstance(res, dict) and \"messages\" in res\n","            else getattr(res, \"content\", str(res))\n","        ).strip()\n","        self.history.extend(\n","            [{\"role\": \"user\", \"content\": q}, {\"role\": \"assistant\", \"content\": reply}]\n","        )\n","        return reply\n","\n","    def reset(self, new_session_id: Optional[str] = None):\n","        self.session_id = new_session_id or f\"session-{uuid4()}\"\n","        self.history.clear()\n","\n","def simulate_users(user_sessions: Dict[str, List[List[str]]]) -> Dict[str, List[ChatSession]]:\n","    \"\"\"\n","    user_sessions = {\n","        \"user_a\": [\n","            [\"Q1\", \"Q2\"],       # session 1 for user_a\n","            [\"Q3\"]              # session 2 for user_a\n","        ],\n","        \"user_b\": [\n","            [\"Qx\", \"Qy\", \"Qz\"]  # session 1 for user_b\n","        ]\n","    }\n","    \"\"\"\n","    runs: Dict[str, List[ChatSession]] = {}\n","    for uid, sessions in user_sessions.items():\n","        runs[uid] = []\n","        for qs in sessions:\n","            chat = ChatSession(user_id=uid)\n","            print(f\"\\n=== User {uid} | {chat.session_id} ===\")\n","            for q in qs:\n","                ans = chat.ask(q)\n","                print(f\"Q: {q}\\nA: {ans[:200]}{'...' if len(ans) > 200 else ''}\\n\")\n","            runs[uid].append(chat)\n","    return runs\n"]},{"cell_type":"code","execution_count":null,"id":"f22ac47d","metadata":{"id":"f22ac47d"},"outputs":[],"source":["scenarios = {\n","    \"alex\": [\n","        [\"Where Kapitalbank is located?\", \"What products does it offer?\"],\n","        [\"Do they have corporate cards?\"]\n","    ],\n","    \"maria\": [\n","        [\"How to open an account online?\", \"What are the fees?\"]\n","    ],\n","    \"sam\": [\n","        [\"Latest news about Kapitalbank?\"],\n","        [\"Exchange rates today?\", \"ATM withdrawal limits?\"]\n","    ],\n","}\n","runs = simulate_users(scenarios)\n","\n","# Access histories if needed:\n","runs[\"alex\"][0].history  # first session for alex\n","runs[\"sam\"][1].history   # second session for sam"]},{"cell_type":"code","execution_count":null,"id":"c3cc7757","metadata":{"id":"c3cc7757"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}