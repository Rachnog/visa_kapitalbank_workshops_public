{"cells":[{"cell_type":"code","execution_count":1,"id":"4b705a6b","metadata":{"id":"4b705a6b","outputId":"eabf1932-78eb-4b1e-b77e-e766dcbf31a8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762029643752,"user_tz":-60,"elapsed":16523,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wefe in /usr/local/lib/python3.12/dist-packages (1.0.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n","Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.7)\n","Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wefe) (1.26.4)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (2.2.2)\n","Requirement already satisfied: plotly>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (6.3.1)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (2.32.4)\n","Requirement already satisfied: scikit-learn>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (1.6.1)\n","Requirement already satisfied: scipy<1.13 in /usr/local/lib/python3.12/dist-packages (from wefe) (1.12.0)\n","Requirement already satisfied: semantic_version>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (2.10.0)\n","Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from wefe) (4.67.1)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->wefe) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->wefe) (2025.2)\n","Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly>=6.0.0->wefe) (2.10.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->wefe) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->wefe) (2.5.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.5.0->wefe) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.5.0->wefe) (3.6.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n"]}],"source":["! pip install -U wefe gensim openai matplotlib"]},{"cell_type":"code","execution_count":2,"id":"80f0a92c","metadata":{"id":"80f0a92c","executionInfo":{"status":"ok","timestamp":1762029643865,"user_tz":-60,"elapsed":19,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[],"source":["import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"code","execution_count":3,"id":"1154e2a7","metadata":{"id":"1154e2a7","outputId":"4375404d-b805-4e3d-96a5-83c4dd42aee4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762029664979,"user_tz":-60,"elapsed":21095,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'query_name': 'Female Terms and Male Terms wrt Arts and Science', 'result': 0.14873626828193673, 'weat': 0.14873626828193673, 'effect_size': 1.6458439250293078, 'p_value': nan}\n"]}],"source":["# pip install -U wefe gensim openai\n","from openai import OpenAI\n","import numpy as np\n","from gensim.models import KeyedVectors\n","from wefe.word_embedding_model import WordEmbeddingModel\n","from wefe.query import Query\n","from wefe.metrics.WEAT import WEAT\n","\n","client = OpenAI()\n","\n","# 1) choose simple target/attribute word sets (Quick Start pattern)\n","targets = [[\"she\",\"woman\",\"girl\"], [\"he\",\"man\",\"boy\"]]\n","attrs   = [[\"poetry\",\"dance\",\"literature\"], [\"math\",\"physics\",\"chemistry\"]]\n","\n","# 2) embed unique vocabulary with OpenAI and build KeyedVectors\n","vocab = sorted({w for group in (targets+attrs) for w in group})\n","embs = client.embeddings.create(model=\"text-embedding-3-small\", input=vocab).data\n","vecs = np.vstack([np.array(d.embedding, dtype=np.float32) for d in embs])\n","\n","kv = KeyedVectors(vector_size=vecs.shape[1])\n","kv.add_vectors(vocab, vecs)\n","\n","model = WordEmbeddingModel(kv, name=\"openai-text-embedding-3-small\")\n","\n","# 3) run WEAT\n","q = Query(target_sets=targets, attribute_sets=attrs,\n","          target_sets_names=[\"Female Terms\",\"Male Terms\"],\n","          attribute_sets_names=[\"Arts\",\"Science\"])\n","\n","res = WEAT().run_query(q, model, calculate_effect_size=True)\n","print(res)  # keys like: 'weat', 'effect_size', 'p_value'\n"]},{"cell_type":"code","execution_count":4,"id":"e3e26179","metadata":{"id":"e3e26179","outputId":"23c94102-331f-450b-8d5b-b38c9dc7fef0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762029676686,"user_tz":-60,"elapsed":11651,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'query_name': 'Female Terms and Male Terms wrt Arts and Science', 'result': 0.14873628815015158, 'weat': 0.14873628815015158, 'effect_size': 1.6458439744688693, 'p_value': 0.019417475728155338}\n"]}],"source":["from wefe.metrics.WEAT import WEAT\n","\n","res = WEAT().run_query(\n","    q,\n","    model,\n","    normalize=True,                 # cosine-ready; recommended\n","    calculate_effect_size=True,\n","    calculate_p_value=True,         # run permutation test\n","    p_value_method=\"approximate\",   # or \"exact\" for small sets\n","    p_value_iterations=100000,      # raise for stability\n","    p_value_verbose=False\n",")\n","print(res)\n"]},{"cell_type":"code","execution_count":5,"id":"63a3de80","metadata":{"id":"63a3de80","outputId":"3df762f7-2947-4264-e435-f983ee614f46","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1762031551805,"user_tz":-60,"elapsed":1875061,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[openai] embedding 180 words with text-embedding-3-small ...\n","[p-values] computing for 6 / 6 strong effects (|d| >= 0.5) with 10,000 permutations ...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-794374039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mq_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mper_model_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_weat_with_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mITERS_HEAVY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p_value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-794374039.py\u001b[0m in \u001b[0;36mrun_weat_with_p\u001b[0;34m(model, q, iters)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_weat_with_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWordEmbeddingModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m# Try approximate first; fall back to exact if missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     r = WEAT().run_query(\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_effect_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mcalculate_p_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"approximate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wefe/metrics/WEAT.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, model, return_effect_size, calculate_p_value, p_value_test_type, p_value_method, p_value_iterations, p_value_verbose, lost_vocabulary_threshold, preprocessors, strategy, normalize, warn_not_found_words, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcalculate_p_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             p_value = self._calc_p_value(\n\u001b[0m\u001b[1;32m    491\u001b[0m                 \u001b[0mtarget_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0mattribute_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattribute_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wefe/metrics/WEAT.py\u001b[0m in \u001b[0;36m_calc_p_value\u001b[0;34m(self, target_embeddings, attribute_embeddings, original_score, iterations, method, test_type, verbose)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mY_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpool_target_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY_i_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 curr_permutation_weat = self._calc_weat(\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0mX_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wefe/metrics/WEAT.py\u001b[0m in \u001b[0;36m_calc_weat\u001b[0;34m(self, X, Y, A, B)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     ) -> np.number:\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0msecond_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_term\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msecond_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wefe/metrics/WEAT.py\u001b[0m in \u001b[0;36m_calc_s\u001b[0;34m(self, w, A, B)\u001b[0m\n\u001b[1;32m    111\u001b[0m     ) -> np.number:\n\u001b[1;32m    112\u001b[0m         \u001b[0mA_mean_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mB_mean_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA_mean_sim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB_mean_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1966\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"integral\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                     \u001b[0;31m# Conversion float -> int should not contain NaN or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/warnings.py\u001b[0m in \u001b[0;36msimplefilter\u001b[0;34m(action, category, lineno, append)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0m_add_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \"\"\"Insert a simple entry into the list of warnings filters (at the front).\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# %%pip install -U wefe gensim pandas numpy openai matplotlib  # (uncomment to install)\n","\n","import os, math, itertools, json, datetime\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from openai import OpenAI\n","from gensim.models import KeyedVectors\n","import gensim.downloader as api\n","from wefe.word_embedding_model import WordEmbeddingModel\n","from wefe.query import Query\n","from wefe.metrics.WEAT import WEAT\n","\n","# ========================\n","# SPEED / SCOPE PRESETS\n","# ========================\n","MODE = \"FAST\"  # \"FAST\" (OpenAI small only), \"BALANCED\" (+ tiny gensim), \"THOROUGH\" (+ big gensim + heavier p-values)\n","\n","if MODE == \"FAST\":\n","    OPENAI_MODELS = [\"text-embedding-3-small\"]\n","    GENSIM_MODELS = []\n","    ITERS_HEAVY = 10_000\n","    TRIAGE_THRESHOLD = 0.5\n","elif MODE == \"BALANCED\":\n","    OPENAI_MODELS = [\"text-embedding-3-small\", \"text-embedding-3-large\"]\n","    GENSIM_MODELS = [\"glove-wiki-gigaword-50\"]  # ~66MB\n","    ITERS_HEAVY = 10_000\n","    TRIAGE_THRESHOLD = 0.5\n","else:  # THOROUGH\n","    OPENAI_MODELS = [\"text-embedding-3-small\",\"text-embedding-3-large\",\"text-embedding-ada-002\"]\n","    GENSIM_MODELS = [\"glove-wiki-gigaword-300\",\"word2vec-google-news-300\",\"fasttext-wiki-news-subwords-300\"]\n","    ITERS_HEAVY = 100_000\n","    TRIAGE_THRESHOLD = 0.5\n","\n","# Toggle LLM-written report\n","LLM_REPORT = True\n","LLM_MODEL  = \"gpt-4o-mini\"  # adjust if desired\n","\n","# ========================\n","# IO & CACHE\n","# ========================\n","OUT_DIR = Path(\"wefe_out\"); OUT_DIR.mkdir(exist_ok=True)\n","CHART_DIR = OUT_DIR / \"charts\"; CHART_DIR.mkdir(exist_ok=True)\n","CACHE_DIR = Path(\".wefe_cache\"); CACHE_DIR.mkdir(exist_ok=True)\n","\n","def _safe_name(s: str) -> str:\n","    return s.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"_\").replace(\"-\", \"_\")\n","\n","def cache_path(model_name: str) -> Path:\n","    return CACHE_DIR / f\"{_safe_name(model_name)}.npz\"\n","\n","def load_cached_kv(model_name: str) -> KeyedVectors | None:\n","    p = cache_path(model_name)\n","    if not p.exists():\n","        return None\n","    data = np.load(p, allow_pickle=True)\n","    vocab = list(data[\"vocab\"])\n","    vecs  = data[\"vectors\"]\n","    kv = KeyedVectors(vector_size=vecs.shape[1])\n","    kv.add_vectors(vocab, vecs.astype(np.float32))\n","    return kv\n","\n","def save_kv(model_name: str, kv: KeyedVectors) -> None:\n","    vocab = list(kv.key_to_index.keys())\n","    vecs  = np.vstack([kv[w] for w in vocab])\n","    np.savez_compressed(cache_path(model_name), vocab=np.array(vocab, dtype=object), vectors=vecs)\n","\n","def to_kv(vocab: List[str], vectors: np.ndarray) -> KeyedVectors:\n","    kv = KeyedVectors(vector_size=vectors.shape[1])\n","    kv.add_vectors(vocab, vectors.astype(np.float32))\n","    return kv\n","\n","# ========================\n","# OPENAI CLIENT\n","# ========================\n","client = OpenAI()  # requires OPENAI_API_KEY in environment\n","\n","def embed_openai_to_kv(model_name: str, vocab: List[str], batch_size: int = 2048) -> KeyedVectors:\n","    cache_key = f\"openai:{model_name}\"\n","    kv_cached = load_cached_kv(cache_key)\n","    if kv_cached is not None and all(w in kv_cached.key_to_index for w in vocab):\n","        return kv_cached\n","\n","    # Embed whole vocabulary (simple & robust)\n","    vecs = []\n","    print(f\"[openai] embedding {len(vocab)} words with {model_name} ...\", flush=True)\n","    for i in range(0, len(vocab), batch_size):\n","        batch = vocab[i:i+batch_size]\n","        out = client.embeddings.create(model=model_name, input=batch)\n","        vecs.extend([np.array(d.embedding, dtype=np.float32) for d in out.data])\n","\n","    kv = to_kv(vocab, np.vstack(vecs))\n","    save_kv(cache_key, kv)\n","    return kv\n","\n","# ========================\n","# GENSIM HELPERS (OOV normalization)\n","# ========================\n","# Map tricky tokens to forms that classic word models commonly contain\n","GLOVE_CANON_MAP = {\n","    \"USA\": \"united_states\",\n","    \"UK\": \"united_kingdom\",\n","    \"upper-class\": \"upper_class\",\n","    \"working-class\": \"working_class\",\n","    \"high-income\": \"high_income\",\n","    \"low-income\": \"low_income\",\n","    \"well-off\": \"well_off\",\n","}\n","\n","def gensim_norm_candidates(token: str) -> List[str]:\n","    t = token\n","    cands = list(dict.fromkeys([\n","        t,\n","        t.lower(),\n","        t.replace(\"-\", \"_\").lower(),\n","        t.replace(\" \", \"_\").lower(),\n","        GLOVE_CANON_MAP.get(t, t).lower(),\n","        GLOVE_CANON_MAP.get(t.replace(\"-\", \"_\"), t).lower(),\n","    ]))\n","    return cands\n","\n","def normalize_query_for_gensim(q: Query, kv: KeyedVectors) -> Tuple[Query, Dict[str, Tuple[int,int]]]:\n","    \"\"\"Return a new Query with tokens replaced by closest gensim-known forms (lowercased/underscored), dropping OOV.\n","       Also return coverage dict: {set_name: (kept, original)}\"\"\"\n","    def norm_set(words: List[str]) -> Tuple[List[str], Tuple[int,int]]:\n","        kept = []\n","        for w in words:\n","            hit = None\n","            for cand in gensim_norm_candidates(w):\n","                if cand in kv.key_to_index:\n","                    hit = cand; break\n","            if hit: kept.append(hit)\n","        return kept, (len(kept), len(words))\n","\n","    sets = []\n","    coverage = {}\n","    for i, arr in enumerate(q.target_sets):\n","        new, cov = norm_set(arr)\n","        sets.append(new)\n","        coverage[f\"target{i+1}\"] = cov\n","    for i, arr in enumerate(q.attribute_sets):\n","        new, cov = norm_set(arr)\n","        sets.append(new)\n","        coverage[f\"attr{i+1}\"] = cov\n","\n","    # if any set becomes empty, keep as empty (WEFE will error); we handle that upstream by skipping\n","    new_q = Query(\n","        target_sets=[sets[0], sets[1]],\n","        attribute_sets=[sets[2], sets[3]],\n","        target_sets_names=q.target_sets_names,\n","        attribute_sets_names=q.attribute_sets_names,\n","    )\n","    return new_q, coverage\n","\n","def safe_load_gensim(model_key: str) -> KeyedVectors | None:\n","    cache_key = f\"gensim:{model_key}\"\n","    kv_cached = load_cached_kv(cache_key)\n","    if kv_cached is not None:\n","        return kv_cached\n","    try:\n","        print(f\"[gensim] loading {model_key} ...\", flush=True)\n","        base = api.load(model_key)  # returns KV or model with .wv\n","        kv = base if isinstance(base, KeyedVectors) else base.wv\n","        save_kv(cache_key, kv)\n","        return kv\n","    except Exception as e:\n","        print(f\"[skip] could not load gensim '{model_key}': {e}\")\n","        return None\n","\n","