{"cells":[{"cell_type":"markdown","id":"232b7718","metadata":{"id":"232b7718"},"source":["# Rebuilding the agent in Langchain"]},{"cell_type":"code","execution_count":1,"id":"3bcc2e7a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3bcc2e7a","executionInfo":{"status":"ok","timestamp":1762007703177,"user_tz":-60,"elapsed":63485,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}},"outputId":"c9680698-796f-4f65-b6dc-366b0d052599"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.38)\n","Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.4)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.10)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n","google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! pip install langsmith openai\n","! pip install -qU requests bs4 lxml chromadb langchain langchain-text-splitters langchain-openai\n","! pip install -qU duckduckgo-search langchain-community ddgs"]},{"cell_type":"code","execution_count":2,"id":"a8ba902b","metadata":{"id":"a8ba902b","executionInfo":{"status":"ok","timestamp":1762007703213,"user_tz":-60,"elapsed":15,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[],"source":["import os\n","\n","os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n","os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_PROJECT\"] = \"\"\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"code","execution_count":3,"id":"958c1550","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"958c1550","executionInfo":{"status":"ok","timestamp":1762007825028,"user_tz":-60,"elapsed":121801,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}},"outputId":"78e33de4-944d-4ae1-c290-353389602ca0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved 39 pages to kapitalbank_pages.json\n","Loaded 39 pages from kapitalbank_pages.json\n","Indexed pages=39 chunks=161 into chroma_kapitalbank/ (collection 'kapitalbank_en')\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2284835735.py:80: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n","  vs.persist()\n","/tmp/ipython-input-2284835735.py:91: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n","  vs = Chroma(\n"]}],"source":["# kb_en_to_chroma.py  — minimal & direct\n","import os, re, time, requests\n","from urllib.parse import urljoin, urldefrag\n","from bs4 import BeautifulSoup\n","\n","BASE = \"https://www.kapitalbank.az\"\n","START = f\"{BASE}/en\"\n","UA = {\"User-Agent\": \"kb-minicrawl/0.2\"}\n","TIMEOUT = 15\n","MAX_PAGES = 50\n","\n","def clean_url(u):\n","    u = urldefrag(u)[0]\n","    if not u: return None\n","    if not u.startswith(\"http\"): u = urljoin(BASE, u)\n","    if not u.startswith(START): return None\n","    if re.search(r\"\\.(pdf|jpe?g|png|gif|svg|mp4|zip|docx?|xlsx?)$\", u, re.I): return None\n","    return u\n","\n","def extract_text(html):\n","    s = BeautifulSoup(html, \"lxml\")\n","    for t in s([\"script\",\"style\",\"noscript\",\"svg\",\"footer\",\"nav\",\"header\"]): t.decompose()\n","    n = s.select_one(\"main\") or s.select_one(\"article\") or s.body or s\n","    return \" \".join((n.get_text(\" \", strip=True) if n else s.get_text(\" \", strip=True)).split())\n","\n","visited, queue, pages = set(), [START], []\n","while queue and len(visited) < MAX_PAGES:\n","    url = queue.pop(0)\n","    if url in visited: continue\n","    try:\n","        r = requests.get(url, headers=UA, timeout=TIMEOUT)\n","        if r.ok and \"text/html\" in r.headers.get(\"Content-Type\",\"\"):\n","            txt = extract_text(r.text)\n","            if len(txt) > 200:\n","                pages.append({\"url\": url, \"text\": txt})\n","            s = BeautifulSoup(r.text, \"lxml\")\n","            for a in s.find_all(\"a\", href=True):\n","                u = clean_url(a[\"href\"])\n","                if u and u not in visited:\n","                    queue.append(u)\n","        visited.add(url); time.sleep(0.15)\n","    except requests.RequestException:\n","        visited.add(url)\n","\n","import json\n","\n","# Save the crawled pages data to a file for later use\n","pages_outfile = \"kapitalbank_pages.json\"\n","with open(pages_outfile, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(pages, f, indent=2, ensure_ascii=False)\n","print(f\"Saved {len(pages)} pages to {pages_outfile}\")\n","\n","# Load crawled pages from JSON file to make them available for Chroma processing\n","with open(pages_outfile, \"r\", encoding=\"utf-8\") as f:\n","    pages = json.load(f)\n","print(f\"Loaded {len(pages)} pages from {pages_outfile}\")\n","\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","\n","# ---- LangChain chunking ----\n","splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n","docs, metas = [], []\n","for p in pages:\n","    for chunk in splitter.split_text(p[\"text\"]):\n","        docs.append(chunk)\n","        metas.append({\"url\": p[\"url\"]})\n","\n","# ---- OpenAI embeddings -> Chroma ----\n","persist_dir = \"chroma_kapitalbank\"\n","emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # cheap & solid\n","vs = Chroma.from_texts(\n","    texts=docs,\n","    embedding=emb,\n","    persist_directory=persist_dir,\n","    collection_name=\"kapitalbank_en\",\n","    metadatas=metas,\n",")\n","vs.persist()\n","print(f\"Indexed pages={len(pages)} chunks={len(docs)} into {persist_dir}/ (collection 'kapitalbank_en')\")\n","\n","from langchain_community.vectorstores import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","\n","persist_dir = \"chroma_kapitalbank\"\n","collection_name = \"kapitalbank_en\"\n","emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n","\n","# Load the existing/persisted Chroma vector store\n","vs = Chroma(\n","    persist_directory=persist_dir,\n","    embedding_function=emb,\n","    collection_name=collection_name\n",")"]},{"cell_type":"code","execution_count":4,"id":"b7243806","metadata":{"id":"b7243806","executionInfo":{"status":"ok","timestamp":1762007825055,"user_tz":-60,"elapsed":16,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[],"source":["# from langsmith import Client\n","# from langchain_core.prompts import ChatPromptTemplate\n","\n","# client = Client()\n","# prompt = ChatPromptTemplate.from_template(\"Answer the user's question using the tools you have. Always check internal knowledge first, then use the web.\")\n","# url = client.push_prompt(\"general-agent-prompt\", object=prompt)\n","# # url is a link to the prompt in the UI\n","# print(url)"]},{"cell_type":"code","execution_count":5,"id":"a884f267","metadata":{"id":"a884f267","executionInfo":{"status":"ok","timestamp":1762007825432,"user_tz":-60,"elapsed":363,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}}},"outputs":[],"source":["from typing import Any, Dict\n","from langsmith import Client, traceable\n","from langchain.chat_models import init_chat_model\n","from langchain_core.tools import create_retriever_tool, tool, render_text_description\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain.agents import create_agent\n","\n","# --- assume your vector store exists as `vs` ---\n","retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n","retrieve_tool = create_retriever_tool(\n","    retriever=retriever,\n","    name=\"retrieve\",\n","    description=\"Search the internal vector store for passages relevant to the user's question.\"\n",")\n","\n","_ddg = DuckDuckGoSearchRun()\n","@tool(\"duckduckgo_search\")\n","def duckduckgo_search(query: str) -> str:\n","    \"\"\"Search the web with DuckDuckGo and return a brief summary of top results.\"\"\"\n","    return _ddg.run(query)\n","\n","model  = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n","client = Client()\n","TOOLS  = [retrieve_tool, duckduckgo_search]\n","\n","@traceable(name=\"agentic_solution\", run_type=\"chain\", tags=[\"rag\",\"tools\"])\n","def agentic_solution(inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:\n","    q: str = inputs[\"question\"]\n","\n","    # 1) Pull + render your LangSmith prompt to a STRING\n","    prompt_tpl = client.pull_prompt(\"general-agent-prompt\")\n","    system_prompt = prompt_tpl.format(tools=render_text_description(TOOLS))\n","\n","    # 2) One-liner agent creation (v1)\n","    agent = create_agent(\n","        model,                    # or \"openai:gpt-4o-mini\"\n","        tools=TOOLS,\n","        system_prompt=system_prompt,  # system prompt accepted directly\n","    )\n","\n","    # 3) Invoke\n","    result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": q}]})\n","    return {\"answer\": result[\"messages\"][-1].content.strip()}\n"]},{"cell_type":"code","execution_count":6,"id":"67b1705d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67b1705d","executionInfo":{"status":"ok","timestamp":1762007831472,"user_tz":-60,"elapsed":6071,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}},"outputId":"afde0183-cfa7-479c-be6b-629c87c350e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'answer': 'Kapitalbank is primarily located in Azerbaijan, where it serves as a significant financial institution. It has multiple branches across the country. Additionally, there are references to Kapital Bank branches in Washington, DC, USA, indicating that there may be a connection or similar naming convention. \\n\\nIf you are looking for a specific branch or more detailed information, please specify the location or context you are interested in.'}\n"]}],"source":["out = agentic_solution({\"question\": 'Where Kapitalbank is located?'})\n","print(out)"]},{"cell_type":"code","execution_count":7,"id":"5cd9cda5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cd9cda5","executionInfo":{"status":"ok","timestamp":1762007831574,"user_tz":-60,"elapsed":22,"user":{"displayName":"Alex Honchar","userId":"16229384722428101359"}},"outputId":"625a2c97-3441-4a5a-b5cc-3d9e31080481"},"outputs":[{"output_type":"stream","name":"stdout","text":["Kapitalbank is primarily located in Azerbaijan, where it serves as a significant financial institution. It has multiple branches across the country. Additionally, there are references to Kapital Bank branches in Washington, DC, USA, indicating that there may be a connection or similar naming convention. \n","\n","If you are looking for a specific branch or more detailed information, please specify the location or context you are interested in.\n"]}],"source":["print(out['answer'])"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}